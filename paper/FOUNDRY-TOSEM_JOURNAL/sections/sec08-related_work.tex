\section{Related Work} \label{sec:related_work}

In this section, we present an overview of existing research related to our work. We position our work within the existing body of knowledge in areas of reengineering of systems into SPL, clone-and-own, variability in SPL and software transplantation. 

\textbf{Reengineering of Software Systems into SPL}. Diverse academic proposals and industrial experience reports addressing reengineering of legacy systems into SPL are present in the literature~\cite{Assuncao2017}. However, this number decreases considerably when we are interested in proposals that automate the lifecycle of the reengineering process~\cite{Kruger2020}. 
 
Martinez et al.~\cite{Martinez2015} introduced \emph{But4Reuse}, a generic and extensible open source tool to facilitate extractive SPL adoption. But4Reuse is a tool that aims to extract SPLs from legacy systems by identifying a set of reusable assets and representing them in a modular way. The tool uses a variety of program analysis techniques, including clone detection and feature location, to identify commonalities and variabilities in the code. Once the SPL is extracted, But4Reuse generates a set of variability models, which can be used to configure the SPL for different product variants. In contrast, \FOUNDRY does not assume an existing set of product variants. 
SPL can be created from a single codebase, and only requires feature entry point annotation, and a set of tests.
The needed code is automatically extracted using slicing, and modified to run in the given product base via automated over-organ adaptation.

\emph{IsiSPL}~\cite{hlad2021} is a reactive approach~\cite{Krueger2001} to SPL adoption. 
IsiSPL automates the integration of new products into an existing SPL and thus generation of a new SPL with the new features.
In particular, whenever a new product is added, a list of all features needs to be provided.
IsiSPL then analyses SPL to only insert new features, annotating them with conditional directives. However, with large number of products inserted over time, the list of conditional directives will grow, hindering code comprehension, maintenance, and ease of derivation of new products. In \FOUNDRY the use of such directives to handle variability is not a mandatory condition to use it. The developer is free to automatically introduce conditional directives in the evolved product line. That is they can also generate a product without surrounding the feature's code with additional directives, simply by transplanting organs from the transplantation platform. 

\textbf{Clone-and-own}. \FOUNDRY can be exploited as an automated alternative to clone-and-own, where, instead of creating a product line, products are cloned and amended, based on demand.
Although there exists automated support for feature detection using code clone detection, its adaptation for reuse still requires manual work~\cite{Yoshimura2006, Kastner2014}. 

Fischer et al.~\cite{Fischer2015}, for instance, present \emph{ECCO} to enhance clone-and-own. 
The tool finds the proper software artifacts to reuse and then provides guidance during manual adaptation phase, by hinting which software artifacts may need to be migrated and adapted. 
Moreover, ECCO requires that the features' source code must be extracted from the same family of products, which limits its ability to reuse assets. 
In contrast, \FOUNDRY stores over-organs that can be automatically adapted to different product bases. These do not need to come from the same family of products as the product base. Once extracted, features implemented by stored over-organs can be adapted, and implanted into a product base in a fully automated way.

\textbf{Variability in SPL.} The capacity of providing variability in a software development process is a key aspect of modern software development, enabling software products to be customized and adapted to meet the needs and requirements of different stakeholders. 

Several works have already identified the frequent use of the \emph{variability mechanisms}, like preprocessor directives~\cite{Liebig2010} and feature flags~\cite{ Kruger2018, Meinicke2020}, as strategies for allowing the inclusion or exclusion of specific code blocks or features in the product line at compile time or runtime. Both are annotation-based implementation techniques for software product lines require explicit annotations often scattered across multiple code units (e.g., preprocessor annotations such as $\texttt{\#IFDEFs}$)~\cite{Apel2013}. 
These annotations establish a mapping of portions of code to features defined in a variability model. This mapping serves as input to the configurator tools, which then uses the information to select and configure the appropriate features for a given software product.

Despite its error-proneness and low abstraction level, the preprocessor directives are still widely used in present-day software projects to implement variability, maintain, evolve, reuse, or re-engineer a software system~\cite{Kruger2018}. Liegib et al.~\cite{Liebig2010} presents a study of 40 SPL that use preprocessor-based variability mechanisms. The study analyzes the variability mechanisms used in the product lines and the impact of these mechanisms on the codebase, in terms of code size, complexity, and maintainability. Christian KÃ¤stner et al.~\cite{Kastner2008} also discuss the concept of variability based on preprocessor directives in software product lines and how it affects the granularity of features. They present a case study of the Linux kernel to illustrate how the different levels of granularity in feature implementation can affect product line evolution and maintenance. 

Other authors, such as, Jezequel et al.~\cite{Jezequel2022} present a case study of how feature models and feature toggles can be used in practice to manage variability in software systems. The authors describe how they used feature models to capture the commonalities and variabilities of a software product line and then translated them into feature toggles that could be used to enable or disable specific features at runtime.

Although useful, these traditional variability mechanisms have limitations~\cite{Bachmann2005, Liebig2010}. Preprocessor directives can lead to code bloat and reduced maintainability, while feature flags can add complexity and overhead to the codebase. Rahman et al.~\cite{Rahman2016} analyzed feature flag usage in the open-source code base behind Google Chrome, finding that feature flags are heavily used but often long-lived, resulting in additional maintenance and technical debt. Meinicke et al.~\cite{Meinicke2020} also discovered that despite the temporary nature of feature toggles and developers' initial intention to remove them, they tend to remain in the codebase unless compelled by policy or technical measures. 

Particularity, building an SPL , where the number of options can grow considerably ~\cite{Lotufo2010,Xu2015}, the use of feature flags and/or preprocessor directives can lead to a large codebase in the emergent product line~\cite{Meinicke2020}. Foundry can be an interesting alternative to those traditional variability techniques. In contrast to the existing approaches where lots of annotations that are permanently added and their number increases over time, our solution requires only an annotation of the feature entry point and its insertion point in the product base. Thus, Foundry's approach has the potential to reduce code complexity and increased readability, as such any extra annotations are not required. Furthermore, Foundry keeps all reusable features of a product line (so-called organs) functional and physically separate, integrating them into the product base only when required for composing a new product.

Overall, ST technique can potentially offer several advantages over the use of traditional feature toggles, including simplified maintenance, reduced code complexity, and reduced risk of conflicts. Furthermore, it can be used in conjunction with existing variability mechanisms like preprocessor directives and feature flags, allowing developers to take advantage of the benefits of both approaches such as the possibility of enabling or disabling organs at runtime or compile-time. 

\textbf{Software Transplantation}. As far as the literature on automated software transplantation is concerned, Petke et al.~\cite{Petke2014,Petke2018} were the first to transplant snipets of code from various versions of the same system to improve its performance, using genetic improvement~\cite{Petke18}. One year later, Barr et al. successfully transplanted a feature from one program into another~\cite{Barr2015}. 

Stelios Sidiroglou-Douskos et al.~\cite{Sidiroglou2017} proposed another tool, CodeCarbonCopy (CCC), which can also transplant code automatically. CCC is a code-transferring tool from a donor into a host codebase. It implements a static analysis that identifies and removes irrelevant functionalists that are irrelevant to the host system. It has performed well in eight code transfers across six applications. However, the code redundancy problem still persists.  CCC is thus unable to handle multiple feature transplantation. Foundry on other hand, addresses this significant problem by exploiting code clone detection. Additionally, CCC inherits the limitations of its static analysis technique~\cite{Bessey2010} to identify the feature codes. It typically only looks at the code in isolation and does not consider the broader context in which the code is used, such as external dependencies or interactions with other features~\cite{Bessey2010, Ilyas2016}.

More recently, Liu et al.~\cite{Liu2018} introduced a method to transplant code from open source software. The validation results indicated that their method can substantially reduce the workload of programmers and is applicable to real-world open-source software. However their idea is also based on program slicing, it does not support the transplant of multiple organs to reengineering of systems into SPL. Furthermore, they still not provide any tool that support their method.

In contract to those works, we are the first to use automated software transplantation to automate SPL engineering tasks. Our approach and tool can transplant multiple organs to compose an SPL from existing donor systems. In the process, we have solved several issues, previously not considered in the software transplantation literature, such as code redundancy, organ dependence and feature interactions.



